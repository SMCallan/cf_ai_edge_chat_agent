# **cf_ai_edge_chat_agent**

<p align="center">
  <img src="./LOGOAG.png" width="160" alt="Project Logo"/>
</p>

A lightweight, edge-native AI chat agent built using **Cloudflare Workers**, **Durable Objects**, and **Workers AI**.
The application serves a minimal HTML/JS chat interface and uses a stateful Durable Object to maintain conversational memory while running Llama-3.3 inference on Workers AI.

This project is submitted as part of the **Cloudflare AI Optional Assignment**.

---

## ğŸš€ Live Demo

**Agent running on Workers:**
ğŸ‘‰ [https://cf_ai_edge_chat_agent.s035187n.workers.dev](https://cf_ai_edge_chat_agent.s035187n.workers.dev)

**GitHub Repository:**
ğŸ‘‰ [https://github.com/SMCallan/cf_ai_edge_chat_agent](https://github.com/SMCallan/cf_ai_edge_chat_agent)

---

## âœ¨ Features

* **âš¡ Edge-native inference** â€” powered by Workers AI (`@cf/meta/llama-3.3-8b-instruct`).
* **ğŸ§  Stateful memory** â€” conversation history stored in a Durable Object.
* **ğŸ§© Minimal, clear codebase** â€” single Worker + DO + tiny static frontend.
* **ğŸŒ Globally distributed** â€” runs close to users automatically.
* **ğŸ“¦ No external backend required** â€” all logic runs inside Cloudflare's platform.

---

## ğŸ§± Architecture Overview

### **1. Cloudflare Worker**

Handles routing and serves static assets.

* `GET /` â†’ returns `public/index.html`
* `POST /chat` â†’ receives `{ message }`, forwards to DO, returns `{ reply }`

### **2. Durable Object â€” `ChatAgentDO`**

Provides per-session memory and conversation management.

* Stores the last N messages in `state.storage`
* Builds a prompt from history
* Calls Workers AI
* Saves and returns assistant output

### **3. Workers AI**

Current model:

```
@cf/meta/llama-3.3-8b-instruct
```

Receives:

* A configurable **system prompt**
* The reconstructed conversation history
* The userâ€™s newest message

### **4. Frontend**

A simple HTML/JS chat UI located in:

```
public/index.html
```

---

## ğŸ“ Directory Structure

```
cf_ai_edge_chat_agent/
â”‚
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ index.html        # Chat UI
â”‚   â”œâ”€â”€ README.md         # (legacy placeholder)
â”‚   â”œâ”€â”€ PROMPTS.md        # Build prompts (copied to root)
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ agent.ts          # Worker + Durable Object logic
â”‚
â”œâ”€â”€ wrangler.toml         # Cloudflare configuration
â”œâ”€â”€ README.md             # You are here
â”œâ”€â”€ PROMPTS.md            # AI prompts used during development
â”œâ”€â”€ LOGOAG.png            # Project logo
â””â”€â”€ package.json
```

---

## ğŸ› ï¸ Getting Started

### **Prerequisites**

* Node.js 18+
* Cloudflare account
* Workers AI enabled
* Durable Objects enabled
* Wrangler (via `npx` or as a dev dependency)

---

### **1. Clone and install**

```bash
git clone https://github.com/SMCallan/cf_ai_edge_chat_agent.git
cd cf_ai_edge_chat_agent
npm install
```

---

### **2. Log in to Cloudflare**

```bash
npx wrangler login
```

---

### **3. Run locally**

```bash
npm run dev
```

Then open:
ğŸ‘‰ [http://localhost:8787](http://localhost:8787)

---

### **4. Deploy**

```bash
npx wrangler deploy
```

Your Worker will be deployed to:

```
https://<worker-name>.<your-account>.workers.dev
```

---

## âš™ï¸ Configuration

### Change the system prompt or model

Modify in `src/agent.ts`:

```ts
const response = await env.AI.run("@cf/meta/llama-3.3-8b-instruct", {
  messages: [
    {
      role: "system",
      content: "You are a concise, friendly assistant running on Cloudflare Workers at the edge.",
    },
    { role: "user", content: prompt },
  ],
});
```

---

## ğŸ§ª Example Request (from the UI)

```js
fetch("/chat", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({ message: "Hello!" }),
});
```

Response:

```json
{
  "reply": "Hi! How can I help you today?"
}
```

---

## ğŸ“Œ Assignment Compliance (Cloudflare Optional AI Project)

This project includes:

âœ” **LLM** â€” Workers AI (Llama 3.3 8B Instruct)
âœ” **Workflow / Coordination** â€” Durable Object controlling prompt + memory
âœ” **User input via chat** â€” HTML/JS chat UI
âœ” **Memory / State** â€” DO stores conversation history
âœ” **Repo prefix** â€” `cf_ai_â€¦`
âœ” **README.md** â€” clear documentation + run instructions
âœ” **PROMPTS.md** â€” transparent prompt history
âœ” **Live deployment** â€” linked above

**â†’ Fully meets assignment criteria.**

---

## ğŸš§ Future Enhancements

These are optional but demonstrate engineering foresight:

* WebSocket streaming responses
* Realtime client sync using `useAgent()`
* Vectorize-powered long-term memory
* Multiple personas selectable in UI
* Cloudflare Pages frontend
* Integration with Cloudflare Workflows for async tasks

---

## ğŸ“„ License

This repository may be used for Cloudflareâ€™s optional assignment or for educational purposes.
You are free to fork or reuse the structure.

---

## ğŸ‘¤ Author

**Callan Smith MacDonald**
GitHub: [https://github.com/SMCallan](https://github.com/SMCallan)
Cloudflare Workers / AI Engineering Enthusiast
